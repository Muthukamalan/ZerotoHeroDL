{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import (\n",
    "    ANCHORS,\n",
    "    S,\n",
    "    PASCAL_CLASSES,\n",
    "    NUM_CLASSES,\n",
    "    CHKPT_FILE,\n",
    "    DEVICE,\n",
    "    NUM_WORKERS,\n",
    "    SAVE_MODEL,\n",
    "    LEARNING_RATE,\n",
    "    WEIGHT_DECAY,\n",
    "    NUM_EPOCHS,\n",
    "    CONF_THRESHOLD,\n",
    "    LOAD_MODEL,\n",
    "    PIN_MEMORY,\n",
    "    IMAGE_SIZE,\n",
    "    BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture Config\n",
    "# tuple: Conv Block\n",
    "# list:  Residual Block represent \"B\" and number of repetations\n",
    "# string:\n",
    "#   S: Scaled Prediction (compute_loss) \n",
    "#   U: Upscale featuremap and concatenate with previous layer\n",
    "config = [\n",
    "    (32, 3, 1),\n",
    "    (64, 3, 2),\n",
    "    [\"B\", 1],\n",
    "    (128, 3, 2),\n",
    "    [\"B\", 2],\n",
    "    (256, 3, 2),\n",
    "    [\"B\", 8],\n",
    "    (512, 3, 2),\n",
    "    [\"B\", 8],\n",
    "    (1024, 3, 2),\n",
    "    [\"B\", 4],  # To this point is Darknet-53\n",
    "    (512, 1, 1),\n",
    "    (1024, 3, 1),\n",
    "    \"S\",\n",
    "    (256, 1, 1),\n",
    "    \"U\",\n",
    "    (256, 1, 1),\n",
    "    (512, 3, 1),\n",
    "    \"S\",\n",
    "    (128, 1, 1),\n",
    "    \"U\",\n",
    "    (128, 1, 1),\n",
    "    (256, 3, 1),\n",
    "    \"S\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muthu\\miniconda3\\envs\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import lightning as pl\n",
    "from torch import nn \n",
    "from lightning.pytorch.utilities.types import STEP_OUTPUT\n",
    "import torch\n",
    "from typing import Any,AnyStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(pl.LightningModule):\n",
    "    def __init__(self,in_channels:int,out_channels:int,bn_act:bool=True,**kwargs:Any) -> None:\n",
    "        '''\n",
    "            # ConvBlock \n",
    "            args:\n",
    "            - in_channels:  input_channels of conv layer\n",
    "            - out_channels: output_channels of conv layer\n",
    "            - bn_act:       wanna use batch_norm and activation function\n",
    "            - **kwargs:     will take care  \n",
    "                - kernel_size:int (required),\n",
    "                - padding:int=0` , \n",
    "                - stride:int=1, \n",
    "                - dilation:int =1 and \n",
    "                - groups:int =1\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels,out_channels=out_channels,bias=False,**kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.LeakyReLU(0.1)\n",
    "        self.use_bn_act = bn_act\n",
    "\n",
    "    def forward(self,x)->torch.Tensor:\n",
    "        '''\n",
    "            x be the input tensor\n",
    "        '''\n",
    "        if self.use_bn_act:\n",
    "            return self.relu(self.bn(self.conv(x)))\n",
    "        else:\n",
    "            return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(pl.LightningModule):\n",
    "    def __init__(self,channels:int, use_residual:bool=True,num_repeats:int=1, **kwargs: Any) -> None:\n",
    "        '''\n",
    "            # Residual Block\n",
    "            args:\n",
    "            - channels:      number of input channels for CNNBlock\n",
    "            - use_residual:  wanna add `input_tensor + residual`\n",
    "            - num_repeats:   number of time residual block gonna repeat\n",
    "\n",
    "            ## Note:\n",
    "            - In Residual Block Internel, \n",
    "                - we reduce number of channels, by 1x1 kernel\n",
    "                - do Feature-MAP by 3x3 kernel and increase number of channels\n",
    "\n",
    "            - In Residual Block Construction,\n",
    "                - construct layer by number of times\n",
    "                - (0-num_repeats): num_repeats x Sequentials\n",
    "                    (\n",
    "                        - [0] CNNBlock\n",
    "                        - [1] CNNBlock\n",
    "                    )\n",
    "                    if residue: x+residue(x)\n",
    "                    else: x\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.num_repeats:int =  num_repeats\n",
    "        self.use_residual:bool = use_residual \n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        for repeat in range(num_repeats):\n",
    "            self.layers += [\n",
    "                nn.Sequential(\n",
    "                    CNNBlock(\n",
    "                        in_channels = channels, \n",
    "                        out_channels= channels//2,        # reduce channels by half by 1x1\n",
    "                        kernel_size=1\n",
    "                    ),\n",
    "                    CNNBlock(\n",
    "                        in_channels= channels//2, \n",
    "                        out_channels= channels,           # Features + increase channels as same 3x3\n",
    "                        kernel_size = 3,\n",
    "                        padding =1 \n",
    "                    )\n",
    "                )\n",
    "            ]\n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            if self.use_residual:\n",
    "                x += layer(x)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScalePrediction(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.pred = nn.Sequential(\n",
    "            CNNBlock(in_channels, 2*in_channels, bn_act=True,kernel_size=3,padding=1),  # increase channels by 2X\n",
    "            CNNBlock(2*in_channels, (self.num_classes +5)*3, bn_act=False, kernel_size=1 )    # prediction_layer: num_anchor_box=3, coordinates+objectness_score=4+1 , number_of_classes\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        # x-> (bs,c,h,w)\n",
    "        print(x.shape)\n",
    "        x = self.pred(x)\n",
    "        print(x.shape)\n",
    "        x = x.reshape(  x.shape[0], 3, self.num_classes+5,  x.shape[2],  x.shape[3])\n",
    "        print(x.shape)\n",
    "        x = x.permute(0,1,3,4,2)\n",
    "        print(x.shape)\n",
    "        return x\n",
    "\n",
    "        # return(\n",
    "        #     self.pred(x)\\\n",
    "        #             .reshape(\n",
    "        #                     x.shape[0], \n",
    "        #                     3, \n",
    "        #                     self.num_classes+5, \n",
    "        #                     x.shape[2], \n",
    "        #                     x.shape[3] )\\\n",
    "        #             .permute(0,1,3,4,2)\n",
    "        # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss import YOLOLoss\n",
    "from data import PASCALDataModule\n",
    "from helpers import one_cycle_lr,check_class_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PASCALDataModule(\"../../../data/PASCAL_VOC/train.csv\",\"../../../data/PASCAL_VOC/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOV3(pl.LightningModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channel=3,\n",
    "            num_classes=NUM_CLASSES,\n",
    "            epochs:int=NUM_EPOCHS,\n",
    "            loss_fn=YOLOLoss,\n",
    "            data_module = PASCALDataModule,\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            weight_decay = WEIGHT_DECAY,\n",
    "            maxlr = None,\n",
    "            scheduler_steps = None,\n",
    "            device_count=NUM_WORKERS,\n",
    "            # device = DEVICE,\n",
    "            )->None:\n",
    "        super().__init__()\n",
    "        self.num_classes   = num_classes\n",
    "        self.in_channels   = in_channel\n",
    "        self.epochs        = epochs\n",
    "        self.loss          = loss_fn()    #instance returned\n",
    "        self.data_module   = data_module  #\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay  = weight_decay\n",
    "        self.max_lr        = maxlr\n",
    "        self.scheduler_step= scheduler_steps\n",
    "        self.device_count  = device_count\n",
    "\n",
    "\n",
    "        self.layers        = self._create_conv_layers()\n",
    "\n",
    "        # S (scaled frame)\n",
    "        # [[[13, 13], [13, 13], [13, 13]],\n",
    "        #  [[26, 26], [26, 26], [26, 26]],\n",
    "        #  [[52, 52], [52, 52], [52, 52]]]\n",
    "\n",
    "        #\n",
    "        self.scaled_anchors= torch.tensor(ANCHORS) * torch.tensor(S).unsqueeze(1).unsqueeze(1).repeat(1,3,2)\n",
    "\n",
    "\n",
    "    def return_layers(self):\n",
    "        return self.layers\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        outputs           = []       # for each scale\n",
    "        route_connections = [] \n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer,ScalePrediction):\n",
    "                outputs.append(layer(x))\n",
    "                continue\n",
    "            \n",
    "            x = layer(x)\n",
    "\n",
    "            if isinstance(layer,ResidualBlock) and layer.num_repeats==8:   # runs only 2 times\n",
    "                route_connections.append(x)\n",
    "            elif isinstance(layer,nn.Upsample):\n",
    "                x = torch.cat([x,route_connections[-1]],dim=1)\n",
    "                route_connections.pop()\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def _create_conv_layers(self):\n",
    "        layers = nn.ModuleList()\n",
    "        in_channels = self.in_channels\n",
    "\n",
    "        for module in config:\n",
    "            # CONV\n",
    "            if isinstance(module,tuple):\n",
    "                out_channels, kernel_size,stride = module\n",
    "                layers.append(\n",
    "                    CNNBlock(\n",
    "                        in_channels,\n",
    "                        out_channels,\n",
    "                        kernel_size=kernel_size,\n",
    "                        stride=stride,\n",
    "                        padding = 1 if kernel_size==3 else 0\n",
    "                        )\n",
    "                ) \n",
    "                in_channels = out_channels\n",
    "            \n",
    "            # RESIDUAL\n",
    "            if isinstance(module,list):\n",
    "                num_repeats = module[1]\n",
    "                layers.append(\n",
    "                    ResidualBlock(in_channels,num_repeats=num_repeats)\n",
    "                ) \n",
    "\n",
    "            # ScaledPrediction / UpScaling\n",
    "            if isinstance(module,str):\n",
    "                if module==\"S\":\n",
    "                    layers+= [\n",
    "                            ResidualBlock(in_channels,use_residual=False,num_repeats=1),\n",
    "                            CNNBlock(in_channels,in_channels//2,kernel_size=1),\n",
    "                            ScalePrediction(in_channels//2,num_classes=self.num_classes)\n",
    "                        ]\n",
    "                    \n",
    "                    in_channels = in_channels//2\n",
    "                elif module==\"U\":\n",
    "                    layers.append( nn.Upsample(scale_factor=2) )\n",
    "                    # increase channel after upscaling\n",
    "                    in_channels = in_channels*3 \n",
    "\n",
    "\n",
    "        return layers\n",
    "\n",
    "\n",
    "\n",
    "    def configure_optimizers(self)->dict:\n",
    "        optimizer = torch.optim.Adam(\n",
    "                            self.parameters(),\n",
    "                            lr = self.learning_rate,\n",
    "                            weight_decay= self.weight_decay\n",
    "                        )\n",
    "        scheduler = one_cycle_lr(\n",
    "            optimizer=optimizer,\n",
    "            maxlr=self.max_lr,steps=self.scheduler_step,epochs=self.epochs\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\":optimizer,\n",
    "            \"lr_scheduler\":{\n",
    "                \"scheduler\":scheduler,\n",
    "                \"interval\":\"step\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _common_step(self,batch,batch_idx):\n",
    "        self.scaled_anchors = self.scaled_anchors.to(self.device)\n",
    "        x,y = batch                    # len(y)=3  \n",
    "        y0, y1, y2 = y[0], y[1], y[2]  # y[i] = (BS, 3, anchor_resolution_{13,26,52},anchor_resolution_{13,26,52}, 6 )\n",
    "\n",
    "        out = self(x)   #model(x)\n",
    "        loss = (\n",
    "            self.loss(out[0],y0, self.scaled_anchors[0])\n",
    "            + self.loss(out[1],y1, self.scaled_anchors[1])\n",
    "            + self.loss(out[2],y2, self.scaled_anchors[2])\n",
    "        )\n",
    "        return loss\n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        loss = self._common_step(batch,batch_idx)\n",
    "        self.log(name=\"trian_loss\",value=loss,on_step=True,on_epoch=True,prog_bar=True)\n",
    "        return loss \n",
    "    \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        loss = self._common_step(batch,batch_idx)\n",
    "        self.log(name=\"val_loss\",value=loss,on_step=True,on_epoch=True,prog_bar=True)\n",
    "        return loss \n",
    "    \n",
    "    # TODO: check_class_accuracy()\n",
    "    def test_step(self,batch,batch_idx):\n",
    "        class_acc , noobj_acc, obj_acc = check_class_accuracy(model=self,loader=self.data_module.test_dataloader(), threshold=CONF_THRESHOLD  ,device=DEVICE )\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"class_acc\":class_acc,\n",
    "                \"noobj_acc\":noobj_acc,\n",
    "                \"obj_acc\":obj_acc\n",
    "            },\n",
    "            prog_bar=True\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLOV3(num_classes=20).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512, 13, 13])\n",
      "torch.Size([2, 75, 13, 13])\n",
      "torch.Size([2, 3, 25, 13, 13])\n",
      "torch.Size([2, 3, 13, 13, 25])\n",
      "torch.Size([2, 256, 26, 26])\n",
      "torch.Size([2, 75, 26, 26])\n",
      "torch.Size([2, 3, 25, 26, 26])\n",
      "torch.Size([2, 3, 26, 26, 25])\n",
      "torch.Size([2, 128, 52, 52])\n",
      "torch.Size([2, 75, 52, 52])\n",
      "torch.Size([2, 3, 25, 52, 52])\n",
      "torch.Size([2, 3, 52, 52, 25])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,3,416,416,device='cuda')\n",
    "out = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512, 13, 13])\n",
      "torch.Size([2, 75, 13, 13])\n",
      "torch.Size([2, 3, 25, 13, 13])\n",
      "torch.Size([2, 3, 13, 13, 25])\n",
      "torch.Size([2, 256, 26, 26])\n",
      "torch.Size([2, 75, 26, 26])\n",
      "torch.Size([2, 3, 25, 26, 26])\n",
      "torch.Size([2, 3, 26, 26, 25])\n",
      "torch.Size([2, 128, 52, 52])\n",
      "torch.Size([2, 75, 52, 52])\n",
      "torch.Size([2, 3, 25, 52, 52])\n",
      "torch.Size([2, 3, 52, 52, 25])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)[0].shape==(2,3,416//32,416//32,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512, 13, 13])\n",
      "torch.Size([2, 75, 13, 13])\n",
      "torch.Size([2, 3, 25, 13, 13])\n",
      "torch.Size([2, 3, 13, 13, 25])\n",
      "torch.Size([2, 256, 26, 26])\n",
      "torch.Size([2, 75, 26, 26])\n",
      "torch.Size([2, 3, 25, 26, 26])\n",
      "torch.Size([2, 3, 26, 26, 25])\n",
      "torch.Size([2, 128, 52, 52])\n",
      "torch.Size([2, 75, 52, 52])\n",
      "torch.Size([2, 3, 25, 52, 52])\n",
      "torch.Size([2, 3, 52, 52, 25])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)[1].shape==(2,3,416//16,416//16,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512, 13, 13])\n",
      "torch.Size([2, 75, 13, 13])\n",
      "torch.Size([2, 3, 25, 13, 13])\n",
      "torch.Size([2, 3, 13, 13, 25])\n",
      "torch.Size([2, 256, 26, 26])\n",
      "torch.Size([2, 75, 26, 26])\n",
      "torch.Size([2, 3, 25, 26, 26])\n",
      "torch.Size([2, 3, 26, 26, 25])\n",
      "torch.Size([2, 128, 52, 52])\n",
      "torch.Size([2, 75, 52, 52])\n",
      "torch.Size([2, 3, 25, 52, 52])\n",
      "torch.Size([2, 3, 52, 52, 25])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)[2].shape==(2,3,416//8,416//8,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): CNNBlock(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (1): CNNBlock(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (2): ResidualBlock(\n",
       "    (layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (1): CNNBlock(\n",
       "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): CNNBlock(\n",
       "    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (4): ResidualBlock(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (1): CNNBlock(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): CNNBlock(\n",
       "    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (6): ResidualBlock(\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (1): CNNBlock(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (7): CNNBlock(\n",
       "    (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (8): ResidualBlock(\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (1): CNNBlock(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (9): CNNBlock(\n",
       "    (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (10): ResidualBlock(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (1): CNNBlock(\n",
       "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (11): CNNBlock(\n",
       "    (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (12): CNNBlock(\n",
       "    (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (13): ResidualBlock(\n",
       "    (layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (1): CNNBlock(\n",
       "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (14): CNNBlock(\n",
       "    (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (15): ScalePrediction(\n",
       "    (pred): Sequential(\n",
       "      (0): CNNBlock(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (1): CNNBlock(\n",
       "        (conv): Conv2d(1024, 75, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (16): CNNBlock(\n",
       "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (17): Upsample(scale_factor=2.0, mode='nearest')\n",
       "  (18): CNNBlock(\n",
       "    (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (19): CNNBlock(\n",
       "    (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (20): ResidualBlock(\n",
       "    (layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (1): CNNBlock(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (21): CNNBlock(\n",
       "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (22): ScalePrediction(\n",
       "    (pred): Sequential(\n",
       "      (0): CNNBlock(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (1): CNNBlock(\n",
       "        (conv): Conv2d(512, 75, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (23): CNNBlock(\n",
       "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (24): Upsample(scale_factor=2.0, mode='nearest')\n",
       "  (25): CNNBlock(\n",
       "    (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (26): CNNBlock(\n",
       "    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (27): ResidualBlock(\n",
       "    (layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): CNNBlock(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (1): CNNBlock(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (28): CNNBlock(\n",
       "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (29): ScalePrediction(\n",
       "    (pred): Sequential(\n",
       "      (0): CNNBlock(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (1): CNNBlock(\n",
       "        (conv): Conv2d(256, 75, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.return_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module =  PASCALDataModule(\n",
    "                    \"../../../data/PASCAL_VOC/train.csv\",\n",
    "                    \"../../../data/PASCAL_VOC/test.csv\"\n",
    "                )\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLOV3(in_channel=3,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    epochs=3,\n",
    "    loss_fn=YOLOLoss,\n",
    "    data_module=data_module,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    maxlr=LEARNING_RATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.6400,  2.8600],\n",
       "         [ 4.9400,  6.2400],\n",
       "         [11.7000, 10.1400]],\n",
       "\n",
       "        [[ 1.8200,  3.9000],\n",
       "         [ 3.9000,  2.8600],\n",
       "         [ 3.6400,  7.5400]],\n",
       "\n",
       "        [[ 1.0400,  1.5600],\n",
       "         [ 2.0800,  3.6400],\n",
       "         [ 4.1600,  3.1200]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.scaled_anchors.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
